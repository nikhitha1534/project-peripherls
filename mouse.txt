import cv2
import mediapipe as mp
import pyautogui
import time
import numpy as np

# Initialize MediaPipe Hand module
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(
    min_detection_confidence=0.7,
    min_tracking_confidence=0.7
)
mp_draw = mp.solutions.drawing_utils

# Get screen size
screen_w, screen_h = pyautogui.size()

# Start webcam
cap = cv2.VideoCapture(0)
cap.set(3, 640)  # Reduce frame width for faster processing
cap.set(4, 480)  # Reduce frame height for faster processing

click_threshold = 30  # Distance for click detection
buffer_zone = 5  # Prevents accidental clicks
last_click_time = 0
click_active = False

# Smoothing for cursor movement
prev_x, prev_y = 0, 0
smooth_factor = 0.2  # Adjust to make movement smoother

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        continue  # Skip if frame is empty

    # Flip image for natural movement
    frame = cv2.flip(frame, 1)
    h, w, _ = frame.shape

    # Convert image to RGB and process
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    result = hands.process(rgb_frame)

    if result.multi_hand_landmarks:
        for hand_landmarks in result.multi_hand_landmarks:
            lm_list = []
            for id, lm in enumerate(hand_landmarks.landmark):
                x, y = int(lm.x * w), int(lm.y * h)
                lm_list.append((x, y))

            if len(lm_list) > 8:
                # Index Finger Tip
                index_x, index_y = lm_list[8]

                # Convert webcam coordinates to screen coordinates
                screen_x = np.interp(index_x, [0, w], [0, screen_w])
                screen_y = np.interp(index_y, [0, h], [0, screen_h])

                # Smooth cursor movement
                smooth_x = prev_x + (screen_x - prev_x) * smooth_factor
                smooth_y = prev_y + (screen_y - prev_y) * smooth_factor

                pyautogui.moveTo(smooth_x, smooth_y)
                prev_x, prev_y = smooth_x, smooth_y

                # Thumb Tip
                thumb_x, thumb_y = lm_list[4]

                # Calculate distance between index and thumb for click detection
                distance = np.hypot(index_x - thumb_x, index_y - thumb_y)

                # Click if fingers are close together
                if distance < click_threshold and not click_active:
                    pyautogui.click()
                    click_active = True
                    last_click_time = time.time()

                # Prevent rapid multiple clicks
                if click_active and time.time() - last_click_time > 0.3:
                    click_active = False

            # Draw Hand Landmarks
            mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)

    # Display the webcam feed
    cv2.imshow("Virtual Mouse", frame)

    # Exit on pressing 'ESC'
    if cv2.waitKey(1) & 0xFF == 27:
        break

cap.release()
cv2.destroyAllWindows()
